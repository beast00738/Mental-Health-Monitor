{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "collapsed_sections": [
        "8yzgc3n410ny"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# downloading the dataset"
      ],
      "metadata": {
        "id": "8yzgc3n410ny"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# # !pip install kaggle\n",
        "# !mkdir ~/.kaggle\n",
        "# # download kaggle.json (from kaggle->account->settings->api->new_Token) and upload in colab first\n",
        "# !cp /content/kaggle.json ~/.kaggle/kaggle.json\n",
        "# !chmod 600 ~/.kaggle/kaggle.json\n",
        "# # # https://www.kaggle.com/datasets/himanshusahu00738/face-emotions-expressions\n",
        "# !kaggle datasets download -d himanshusahu00738/face-emotions-expressions\n",
        "# # relpace the name with downladed zip file name\n",
        "# !unzip face-emotions-expressions.zip"
      ],
      "metadata": {
        "id": "Zx3JuSnh17RD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a03174f4-d2ff-4b8f-8f60-3d081c21a631"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mkdir: cannot create directory ‘/root/.kaggle’: File exists\n",
            "face-emotions-expressions.zip: Skipping, found more recently modified local copy (use --force to force download)\n",
            "Archive:  face-emotions-expressions.zip\n",
            "replace test/angry/PrivateTest_10131363.jpg? [y]es, [n]o, [A]ll, [N]one, [r]ename: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# importing Libraries"
      ],
      "metadata": {
        "id": "E-MwYmvQ6FN6"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "sCV30xyVhFbE"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from keras.preprocessing.image import ImageDataGenerator"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "FIleuCAjoFD8",
        "outputId": "28e8c06e-a5dd-4a35-bd99-9e325c1f3d5e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'2.12.0'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "tf.__version__"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Preprocessing"
      ],
      "metadata": {
        "id": "B7mcAjeD2142"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MvE-heJNo3GG"
      },
      "source": [
        "## Preprocessing the Training set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "0koUcJMJpEBD",
        "outputId": "96965fa1-afd0-4759-d8dc-817abaeb4922",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 45936 images belonging to 7 classes.\n"
          ]
        }
      ],
      "source": [
        "target_size=(48, 48)\n",
        "batch_size=32\n",
        "\n",
        "trainValidation_data_generator = ImageDataGenerator(\n",
        "  # rescale=1./225,\n",
        "  rotation_range=10,  # Randomly rotate images by up to 10 degrees\n",
        "  zoom_range=0.2,  # Randomly zoom images by up to 20%\n",
        "  width_shift_range=0.1,  # Randomly shift images horizontally by up to 10% of the image width\n",
        "  height_shift_range=0.1,  # Randomly shift images vertically by up to 10% of the image height\n",
        "  shear_range=0.2,  # Randomly apply shearing transformations\n",
        "  horizontal_flip=True,  # Randomly flip images horizontally\n",
        "  fill_mode='nearest',  # Fill in missing pixels with the nearest value\n",
        "  # preprocessing_function=grayscale_RGB_and_upsizing,\n",
        "  validation_split=0.2    # set the validation split                                \n",
        ")\n",
        "training_set = trainValidation_data_generator.flow_from_directory(\n",
        "                                                            directory='/content/training', \n",
        "                                                            target_size=target_size,\n",
        "                                                            batch_size=batch_size,\n",
        "                                                            class_mode='categorical', \n",
        "                                                            color_mode='rgb', \n",
        "                                                            shuffle=True, \n",
        "                                                            subset='training' # set as training data\n",
        "                                                        )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mrCMmGw9pHys"
      },
      "source": [
        "## Preprocessing the Test set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "SH4WzfOhpKc3",
        "outputId": "02c07024-a3b0-43fd-e148-93bfa9c8c325",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 14356 images belonging to 7 classes.\n"
          ]
        }
      ],
      "source": [
        "test_data_generator = ImageDataGenerator(\n",
        "    # rescale = 1./255\n",
        ")\n",
        "test_set = test_data_generator.flow_from_directory(\n",
        "  directory='/content/test', \n",
        "  target_size=target_size,\n",
        "  class_mode='categorical', \n",
        "  color_mode='rgb',\n",
        "  shuffle=False, \n",
        "  batch_size=batch_size\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Analysis"
      ],
      "metadata": {
        "id": "cPeh5N9V7AVj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class_dictionary = training_set.class_indices\n",
        "class_keys   = list(training_set.class_indices.keys())\n",
        "class_values = list(training_set.class_indices.values())\n",
        "class_count  = len(class_keys)"
      ],
      "metadata": {
        "id": "yqcT6koT7Fgi"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(class_dictionary  )\n",
        "print(class_keys  )\n",
        "print(class_values)\n",
        "print(class_count )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kB6OThXG7K-e",
        "outputId": "8c37605b-2549-4112-d3c7-63d555dce929"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'angry': 0, 'disgust': 1, 'fear': 2, 'happy': 3, 'neutral': 4, 'sad': 5, 'surprise': 6}\n",
            "['angry', 'disgust', 'fear', 'happy', 'neutral', 'sad', 'surprise']\n",
            "[0, 1, 2, 3, 4, 5, 6]\n",
            "7\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Buliding CNN"
      ],
      "metadata": {
        "id": "GrZhkXS7YFoD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow import keras\n",
        "from sklearn import set_config\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "from keras.preprocessing.image import ImageDataGenerator as ImgDataGen\n",
        "from keras.layers import Flatten, Dense, Dropout, Conv2D, MaxPooling2D, Activation, BatchNormalization\n",
        "from keras.models import Sequential, load_model\n",
        "\n",
        "from keras import layers, optimizers, metrics, regularizers, models\n",
        "from keras.optimizers import Adam, Adamax\n",
        "# from tensorflow.keras.metrics import categorical_crossentropy, sparse_categorical_crossentropy"
      ],
      "metadata": {
        "id": "BGnYj_15YJyM"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# define the image shape for the input layer\n",
        "input_shape=(target_size[0], target_size[1], 3)\n",
        "batch_size = batch_size\n",
        "epochs=80\n",
        "# ask_epoch=0"
      ],
      "metadata": {
        "id": "Q9RI0zDbYhbU"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import Model\n",
        "model_name='EfficientNetB3'\n",
        "base_model=tf.keras.applications.efficientnet.EfficientNetB3(\n",
        "  include_top=False, \n",
        "  weights=\"imagenet\",\n",
        "  input_shape=input_shape, \n",
        "  pooling='max'\n",
        ")\n",
        "\n",
        "# Let's make our base_model trainable to get better results\n",
        "base_model.trainable=True\n",
        "x=base_model.output\n",
        "\n",
        "x=BatchNormalization(\n",
        "  axis=-1, \n",
        "  momentum=0.99, \n",
        "  epsilon=0.001,\n",
        "  name='batch_norm_x' \n",
        ")(x)\n",
        "\n",
        "x = Dense(\n",
        "  256, \n",
        "  kernel_regularizer = regularizers.l2(l = 0.016),\n",
        "  activity_regularizer=regularizers.l1(0.006),\n",
        "  bias_regularizer=regularizers.l1(0.006),\n",
        "  activation='relu',\n",
        "  name='dense_x'\n",
        ")(x)\n",
        "\n",
        "x=Dropout(\n",
        "  rate=.4, \n",
        "  seed=123,\n",
        "  name='dropout_x'\n",
        ")(x)  \n",
        "      \n",
        "output=Dense(\n",
        "  class_count, \n",
        "  activation='softmax',\n",
        "  name='dense_output'\n",
        ")(x)\n",
        "\n",
        "cnn_model=Model(inputs=base_model.input, outputs=output, name=model_name)\n",
        "learning_rate=.001 # start with this learning rate\n",
        "cnn_model.compile(\n",
        "  Adamax(learning_rate=learning_rate), \n",
        "  loss='categorical_crossentropy', \n",
        "  metrics=['accuracy']\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7mVaOg1tYjdT",
        "outputId": "74be37f6-2810-4602-9070-f6969059695d"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/keras-applications/efficientnetb3_notop.h5\n",
            "43941136/43941136 [==============================] - 2s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training the CNN"
      ],
      "metadata": {
        "id": "8BxjkaikZrYm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def checkpoint_path(model_name):\n",
        "    checkpoint_path = \"/content/models/\"+model_name+\".ckpt\"\n",
        "    return checkpoint_path\n",
        "\n",
        "check_point = tf.keras.callbacks.ModelCheckpoint(\n",
        "  filepath=checkpoint_path(model_name),\n",
        "  save_weights_only=True,\n",
        "  save_best_only=True, \n",
        "  monitor=\"val_accuracy\",\n",
        "  verbose = 1,\n",
        ")\n",
        "\n",
        "reduce_learning = tf.keras.callbacks.ReduceLROnPlateau(\n",
        "  monitor=\"val_accuracy\", \n",
        "  # factor=0.5, \n",
        "  patience=2,\n",
        "  verbose=1\n",
        ")\n",
        "\n",
        "early_stop = tf.keras.callbacks.EarlyStopping(\n",
        "  monitor=\"val_accuracy\", \n",
        "  min_delta=0.0005,\n",
        "  patience=11, \n",
        "  verbose=1,\n",
        "  restore_best_weights=True\n",
        ")\n",
        "callbacks = [\n",
        "            check_point,\n",
        "            reduce_learning, \n",
        "            # early_stop, \n",
        "          ]"
      ],
      "metadata": {
        "id": "qFOB4xr7awf0"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "# starting the Checkpoint for the model\n",
        "e_checkpoint_path = \"/content/models/fedav_best_model.h5\"\n",
        "checkpoint_dir = os.path.dirname(e_checkpoint_path)\n",
        "\n",
        "e_check_point = tf.keras.callbacks.ModelCheckpoint(\n",
        "                                          filepath=e_checkpoint_path,\n",
        "                                          save_weights_only=True,\n",
        "                                          save_best_only=True, \n",
        "                                          monitor=\"val_accuracy\",\n",
        "                                          verbose = 1,\n",
        "                                        )\n",
        "\n",
        "e_reduce_learning = tf.keras.callbacks.ReduceLROnPlateau(\n",
        "                                            monitor=\"val_accuracy\", \n",
        "                                            # factor=0.5, \n",
        "                                            patience=2,\n",
        "                                            verbose=1\n",
        "                                            )\n",
        "\n",
        "e_early_stop = tf.keras.callbacks.EarlyStopping(\n",
        "                                       monitor=\"val_accuracy\", \n",
        "                                       min_delta=0.0005,\n",
        "                                       patience=11, \n",
        "                                       verbose=1,\n",
        "                                       restore_best_weights=True\n",
        "                                       )\n",
        "\n",
        "e_callbacks = [\n",
        "#             e_check_point,\n",
        "            e_reduce_learning, \n",
        "            # e_early_stop, \n",
        "          ]"
      ],
      "metadata": {
        "id": "bJr-yz0Arrsd"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cnn_model.fit(\n",
        "  x=training_set,  \n",
        "  validation_data= test_set,\n",
        "  steps_per_epoch=training_set.n//training_set.batch_size,\n",
        "  epochs=epochs, \n",
        "  verbose=1, \n",
        "  callbacks=callbacks,  \n",
        "  #   validation_steps=None, \n",
        "  validation_steps= test_set.n//test_set.batch_size,\n",
        ") "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SsrYPi0HZwrT",
        "outputId": "d8edb319-abeb-49b1-da88-0963bf210fed"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/80\n",
            "1435/1435 [==============================] - ETA: 0s - loss: 4.5404 - accuracy: 0.3650\n",
            "Epoch 1: val_accuracy improved from -inf to 0.47726, saving model to /content/models/EfficientNetB3.ckpt\n",
            "1435/1435 [==============================] - 176s 106ms/step - loss: 4.5404 - accuracy: 0.3650 - val_loss: 2.0607 - val_accuracy: 0.4773 - lr: 0.0010\n",
            "Epoch 2/80\n",
            "1435/1435 [==============================] - ETA: 0s - loss: 1.6745 - accuracy: 0.4927\n",
            "Epoch 2: val_accuracy improved from 0.47726 to 0.54143, saving model to /content/models/EfficientNetB3.ckpt\n",
            "1435/1435 [==============================] - 139s 97ms/step - loss: 1.6745 - accuracy: 0.4927 - val_loss: 1.3948 - val_accuracy: 0.5414 - lr: 0.0010\n",
            "Epoch 3/80\n",
            "1435/1435 [==============================] - ETA: 0s - loss: 1.4034 - accuracy: 0.5423\n",
            "Epoch 3: val_accuracy improved from 0.54143 to 0.56166, saving model to /content/models/EfficientNetB3.ckpt\n",
            "1435/1435 [==============================] - 140s 97ms/step - loss: 1.4034 - accuracy: 0.5423 - val_loss: 1.3233 - val_accuracy: 0.5617 - lr: 0.0010\n",
            "Epoch 4/80\n",
            "1435/1435 [==============================] - ETA: 0s - loss: 1.3302 - accuracy: 0.5663\n",
            "Epoch 4: val_accuracy improved from 0.56166 to 0.60345, saving model to /content/models/EfficientNetB3.ckpt\n",
            "1435/1435 [==============================] - 141s 98ms/step - loss: 1.3302 - accuracy: 0.5663 - val_loss: 1.2174 - val_accuracy: 0.6034 - lr: 0.0010\n",
            "Epoch 5/80\n",
            "1435/1435 [==============================] - ETA: 0s - loss: 1.2578 - accuracy: 0.5949\n",
            "Epoch 5: val_accuracy improved from 0.60345 to 0.60414, saving model to /content/models/EfficientNetB3.ckpt\n",
            "1435/1435 [==============================] - 140s 97ms/step - loss: 1.2578 - accuracy: 0.5949 - val_loss: 1.2228 - val_accuracy: 0.6041 - lr: 0.0010\n",
            "Epoch 6/80\n",
            "1435/1435 [==============================] - ETA: 0s - loss: 1.1966 - accuracy: 0.6154\n",
            "Epoch 6: val_accuracy improved from 0.60414 to 0.61970, saving model to /content/models/EfficientNetB3.ckpt\n",
            "1435/1435 [==============================] - 150s 105ms/step - loss: 1.1966 - accuracy: 0.6154 - val_loss: 1.1800 - val_accuracy: 0.6197 - lr: 0.0010\n",
            "Epoch 7/80\n",
            "1435/1435 [==============================] - ETA: 0s - loss: 1.1355 - accuracy: 0.6391\n",
            "Epoch 7: val_accuracy improved from 0.61970 to 0.63058, saving model to /content/models/EfficientNetB3.ckpt\n",
            "1435/1435 [==============================] - 138s 96ms/step - loss: 1.1355 - accuracy: 0.6391 - val_loss: 1.1270 - val_accuracy: 0.6306 - lr: 0.0010\n",
            "Epoch 8/80\n",
            "1435/1435 [==============================] - ETA: 0s - loss: 1.0903 - accuracy: 0.6537\n",
            "Epoch 8: val_accuracy did not improve from 0.63058\n",
            "1435/1435 [==============================] - 137s 95ms/step - loss: 1.0903 - accuracy: 0.6537 - val_loss: 1.1551 - val_accuracy: 0.6244 - lr: 0.0010\n",
            "Epoch 9/80\n",
            "1435/1435 [==============================] - ETA: 0s - loss: 1.0418 - accuracy: 0.6705\n",
            "Epoch 9: val_accuracy improved from 0.63058 to 0.63163, saving model to /content/models/EfficientNetB3.ckpt\n",
            "1435/1435 [==============================] - 137s 95ms/step - loss: 1.0418 - accuracy: 0.6705 - val_loss: 1.1387 - val_accuracy: 0.6316 - lr: 0.0010\n",
            "Epoch 10/80\n",
            "1435/1435 [==============================] - ETA: 0s - loss: 1.0117 - accuracy: 0.6799\n",
            "Epoch 10: val_accuracy improved from 0.63163 to 0.63874, saving model to /content/models/EfficientNetB3.ckpt\n",
            "1435/1435 [==============================] - 150s 104ms/step - loss: 1.0117 - accuracy: 0.6799 - val_loss: 1.1121 - val_accuracy: 0.6387 - lr: 0.0010\n",
            "Epoch 11/80\n",
            "1435/1435 [==============================] - ETA: 0s - loss: 0.9657 - accuracy: 0.6966\n",
            "Epoch 11: val_accuracy improved from 0.63874 to 0.65695, saving model to /content/models/EfficientNetB3.ckpt\n",
            "1435/1435 [==============================] - 136s 95ms/step - loss: 0.9657 - accuracy: 0.6966 - val_loss: 1.0433 - val_accuracy: 0.6569 - lr: 0.0010\n",
            "Epoch 12/80\n",
            "1435/1435 [==============================] - ETA: 0s - loss: 0.9137 - accuracy: 0.7156\n",
            "Epoch 12: val_accuracy did not improve from 0.65695\n",
            "1435/1435 [==============================] - 137s 95ms/step - loss: 0.9137 - accuracy: 0.7156 - val_loss: 1.0972 - val_accuracy: 0.6449 - lr: 0.0010\n",
            "Epoch 13/80\n",
            "1435/1435 [==============================] - ETA: 0s - loss: 0.8774 - accuracy: 0.7285\n",
            "Epoch 13: val_accuracy did not improve from 0.65695\n",
            "\n",
            "Epoch 13: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
            "1435/1435 [==============================] - 138s 96ms/step - loss: 0.8774 - accuracy: 0.7285 - val_loss: 1.0907 - val_accuracy: 0.6525 - lr: 0.0010\n",
            "Epoch 14/80\n",
            "1435/1435 [==============================] - ETA: 0s - loss: 0.7978 - accuracy: 0.7563\n",
            "Epoch 14: val_accuracy improved from 0.65695 to 0.66162, saving model to /content/models/EfficientNetB3.ckpt\n",
            "1435/1435 [==============================] - 139s 97ms/step - loss: 0.7978 - accuracy: 0.7563 - val_loss: 1.0649 - val_accuracy: 0.6616 - lr: 1.0000e-04\n",
            "Epoch 15/80\n",
            "1435/1435 [==============================] - ETA: 0s - loss: 0.7678 - accuracy: 0.7642\n",
            "Epoch 15: val_accuracy improved from 0.66162 to 0.66574, saving model to /content/models/EfficientNetB3.ckpt\n",
            "1435/1435 [==============================] - 139s 97ms/step - loss: 0.7678 - accuracy: 0.7642 - val_loss: 1.0558 - val_accuracy: 0.6657 - lr: 1.0000e-04\n",
            "Epoch 16/80\n",
            "1435/1435 [==============================] - ETA: 0s - loss: 0.7450 - accuracy: 0.7713\n",
            "Epoch 16: val_accuracy did not improve from 0.66574\n",
            "1435/1435 [==============================] - 138s 96ms/step - loss: 0.7450 - accuracy: 0.7713 - val_loss: 1.0801 - val_accuracy: 0.6622 - lr: 1.0000e-04\n",
            "Epoch 17/80\n",
            "1435/1435 [==============================] - ETA: 0s - loss: 0.7334 - accuracy: 0.7752\n",
            "Epoch 17: val_accuracy did not improve from 0.66574\n",
            "\n",
            "Epoch 17: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
            "1435/1435 [==============================] - 138s 96ms/step - loss: 0.7334 - accuracy: 0.7752 - val_loss: 1.0734 - val_accuracy: 0.6618 - lr: 1.0000e-04\n",
            "Epoch 18/80\n",
            "1435/1435 [==============================] - ETA: 0s - loss: 0.7250 - accuracy: 0.7785\n",
            "Epoch 18: val_accuracy did not improve from 0.66574\n",
            "1435/1435 [==============================] - 138s 96ms/step - loss: 0.7250 - accuracy: 0.7785 - val_loss: 1.0749 - val_accuracy: 0.6634 - lr: 1.0000e-05\n",
            "Epoch 19/80\n",
            "1435/1435 [==============================] - ETA: 0s - loss: 0.7198 - accuracy: 0.7805\n",
            "Epoch 19: val_accuracy did not improve from 0.66574\n",
            "\n",
            "Epoch 19: ReduceLROnPlateau reducing learning rate to 1.0000000656873453e-06.\n",
            "1435/1435 [==============================] - 137s 96ms/step - loss: 0.7198 - accuracy: 0.7805 - val_loss: 1.0700 - val_accuracy: 0.6652 - lr: 1.0000e-05\n",
            "Epoch 20/80\n",
            "1435/1435 [==============================] - ETA: 0s - loss: 0.7139 - accuracy: 0.7807\n",
            "Epoch 20: val_accuracy did not improve from 0.66574\n",
            "1435/1435 [==============================] - 141s 98ms/step - loss: 0.7139 - accuracy: 0.7807 - val_loss: 1.0761 - val_accuracy: 0.6629 - lr: 1.0000e-06\n",
            "Epoch 21/80\n",
            "1435/1435 [==============================] - ETA: 0s - loss: 0.7147 - accuracy: 0.7809\n",
            "Epoch 21: val_accuracy did not improve from 0.66574\n",
            "\n",
            "Epoch 21: ReduceLROnPlateau reducing learning rate to 1.0000001111620805e-07.\n",
            "1435/1435 [==============================] - 138s 96ms/step - loss: 0.7147 - accuracy: 0.7809 - val_loss: 1.0724 - val_accuracy: 0.6637 - lr: 1.0000e-06\n",
            "Epoch 22/80\n",
            "1435/1435 [==============================] - ETA: 0s - loss: 0.7112 - accuracy: 0.7846\n",
            "Epoch 22: val_accuracy did not improve from 0.66574\n",
            "1435/1435 [==============================] - 137s 95ms/step - loss: 0.7112 - accuracy: 0.7846 - val_loss: 1.0775 - val_accuracy: 0.6622 - lr: 1.0000e-07\n",
            "Epoch 23/80\n",
            "1435/1435 [==============================] - ETA: 0s - loss: 0.7177 - accuracy: 0.7806\n",
            "Epoch 23: val_accuracy did not improve from 0.66574\n",
            "\n",
            "Epoch 23: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-08.\n",
            "1435/1435 [==============================] - 140s 97ms/step - loss: 0.7177 - accuracy: 0.7806 - val_loss: 1.0757 - val_accuracy: 0.6620 - lr: 1.0000e-07\n",
            "Epoch 24/80\n",
            "1435/1435 [==============================] - ETA: 0s - loss: 0.7131 - accuracy: 0.7840\n",
            "Epoch 24: val_accuracy did not improve from 0.66574\n",
            "1435/1435 [==============================] - 138s 96ms/step - loss: 0.7131 - accuracy: 0.7840 - val_loss: 1.0804 - val_accuracy: 0.6639 - lr: 1.0000e-08\n",
            "Epoch 25/80\n",
            "1435/1435 [==============================] - ETA: 0s - loss: 0.7131 - accuracy: 0.7820\n",
            "Epoch 25: val_accuracy did not improve from 0.66574\n",
            "\n",
            "Epoch 25: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-09.\n",
            "1435/1435 [==============================] - 137s 95ms/step - loss: 0.7131 - accuracy: 0.7820 - val_loss: 1.0776 - val_accuracy: 0.6616 - lr: 1.0000e-08\n",
            "Epoch 26/80\n",
            "1435/1435 [==============================] - ETA: 0s - loss: 0.7165 - accuracy: 0.7825\n",
            "Epoch 26: val_accuracy did not improve from 0.66574\n",
            "1435/1435 [==============================] - 138s 96ms/step - loss: 0.7165 - accuracy: 0.7825 - val_loss: 1.0742 - val_accuracy: 0.6620 - lr: 1.0000e-09\n",
            "Epoch 27/80\n",
            "1435/1435 [==============================] - ETA: 0s - loss: 0.7155 - accuracy: 0.7811\n",
            "Epoch 27: val_accuracy did not improve from 0.66574\n",
            "\n",
            "Epoch 27: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-10.\n",
            "1435/1435 [==============================] - 137s 95ms/step - loss: 0.7155 - accuracy: 0.7811 - val_loss: 1.0801 - val_accuracy: 0.6627 - lr: 1.0000e-09\n",
            "Epoch 28/80\n",
            "1435/1435 [==============================] - ETA: 0s - loss: 0.7145 - accuracy: 0.7814\n",
            "Epoch 28: val_accuracy did not improve from 0.66574\n",
            "1435/1435 [==============================] - 139s 96ms/step - loss: 0.7145 - accuracy: 0.7814 - val_loss: 1.0789 - val_accuracy: 0.6628 - lr: 1.0000e-10\n",
            "Epoch 29/80\n",
            "1435/1435 [==============================] - ETA: 0s - loss: 0.7119 - accuracy: 0.7838\n",
            "Epoch 29: val_accuracy did not improve from 0.66574\n",
            "\n",
            "Epoch 29: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-11.\n",
            "1435/1435 [==============================] - 141s 98ms/step - loss: 0.7119 - accuracy: 0.7838 - val_loss: 1.0783 - val_accuracy: 0.6626 - lr: 1.0000e-10\n",
            "Epoch 30/80\n",
            "1435/1435 [==============================] - ETA: 0s - loss: 0.7118 - accuracy: 0.7824\n",
            "Epoch 30: val_accuracy did not improve from 0.66574\n",
            "1435/1435 [==============================] - 140s 97ms/step - loss: 0.7118 - accuracy: 0.7824 - val_loss: 1.0765 - val_accuracy: 0.6618 - lr: 1.0000e-11\n",
            "Epoch 31/80\n",
            "1435/1435 [==============================] - ETA: 0s - loss: 0.7210 - accuracy: 0.7796\n",
            "Epoch 31: val_accuracy did not improve from 0.66574\n",
            "\n",
            "Epoch 31: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-12.\n",
            "1435/1435 [==============================] - 141s 98ms/step - loss: 0.7210 - accuracy: 0.7796 - val_loss: 1.0775 - val_accuracy: 0.6618 - lr: 1.0000e-11\n",
            "Epoch 32/80\n",
            "1435/1435 [==============================] - ETA: 0s - loss: 0.7166 - accuracy: 0.7817\n",
            "Epoch 32: val_accuracy did not improve from 0.66574\n",
            "1435/1435 [==============================] - 138s 96ms/step - loss: 0.7166 - accuracy: 0.7817 - val_loss: 1.0752 - val_accuracy: 0.6632 - lr: 1.0000e-12\n",
            "Epoch 33/80\n",
            "1435/1435 [==============================] - ETA: 0s - loss: 0.7113 - accuracy: 0.7851\n",
            "Epoch 33: val_accuracy did not improve from 0.66574\n",
            "\n",
            "Epoch 33: ReduceLROnPlateau reducing learning rate to 1.0000001044244145e-13.\n",
            "1435/1435 [==============================] - 139s 97ms/step - loss: 0.7113 - accuracy: 0.7851 - val_loss: 1.0785 - val_accuracy: 0.6632 - lr: 1.0000e-12\n",
            "Epoch 34/80\n",
            "1435/1435 [==============================] - ETA: 0s - loss: 0.7143 - accuracy: 0.7824\n",
            "Epoch 34: val_accuracy did not improve from 0.66574\n",
            "1435/1435 [==============================] - 137s 96ms/step - loss: 0.7143 - accuracy: 0.7824 - val_loss: 1.0696 - val_accuracy: 0.6638 - lr: 1.0000e-13\n",
            "Epoch 35/80\n",
            "1435/1435 [==============================] - ETA: 0s - loss: 0.7125 - accuracy: 0.7818\n",
            "Epoch 35: val_accuracy did not improve from 0.66574\n",
            "\n",
            "Epoch 35: ReduceLROnPlateau reducing learning rate to 1.0000001179769417e-14.\n",
            "1435/1435 [==============================] - 138s 96ms/step - loss: 0.7125 - accuracy: 0.7818 - val_loss: 1.0754 - val_accuracy: 0.6627 - lr: 1.0000e-13\n",
            "Epoch 36/80\n",
            "1435/1435 [==============================] - ETA: 0s - loss: 0.7202 - accuracy: 0.7789\n",
            "Epoch 36: val_accuracy did not improve from 0.66574\n",
            "1435/1435 [==============================] - 137s 96ms/step - loss: 0.7202 - accuracy: 0.7789 - val_loss: 1.0763 - val_accuracy: 0.6631 - lr: 1.0000e-14\n",
            "Epoch 37/80\n",
            "1435/1435 [==============================] - ETA: 0s - loss: 0.7147 - accuracy: 0.7825\n",
            "Epoch 37: val_accuracy did not improve from 0.66574\n",
            "\n",
            "Epoch 37: ReduceLROnPlateau reducing learning rate to 1.0000001518582595e-15.\n",
            "1435/1435 [==============================] - 137s 95ms/step - loss: 0.7147 - accuracy: 0.7825 - val_loss: 1.0759 - val_accuracy: 0.6629 - lr: 1.0000e-14\n",
            "Epoch 38/80\n",
            "1435/1435 [==============================] - ETA: 0s - loss: 0.7190 - accuracy: 0.7812\n",
            "Epoch 38: val_accuracy did not improve from 0.66574\n",
            "1435/1435 [==============================] - 137s 95ms/step - loss: 0.7190 - accuracy: 0.7812 - val_loss: 1.0741 - val_accuracy: 0.6627 - lr: 1.0000e-15\n",
            "Epoch 39/80\n",
            "1435/1435 [==============================] - ETA: 0s - loss: 0.7117 - accuracy: 0.7827\n",
            "Epoch 39: val_accuracy did not improve from 0.66574\n",
            "\n",
            "Epoch 39: ReduceLROnPlateau reducing learning rate to 1.0000001095066122e-16.\n",
            "1435/1435 [==============================] - 135s 94ms/step - loss: 0.7117 - accuracy: 0.7827 - val_loss: 1.0754 - val_accuracy: 0.6622 - lr: 1.0000e-15\n",
            "Epoch 40/80\n",
            "1435/1435 [==============================] - ETA: 0s - loss: 0.7143 - accuracy: 0.7830\n",
            "Epoch 40: val_accuracy did not improve from 0.66574\n",
            "1435/1435 [==============================] - 136s 95ms/step - loss: 0.7143 - accuracy: 0.7830 - val_loss: 1.0752 - val_accuracy: 0.6634 - lr: 1.0000e-16\n",
            "Epoch 41/80\n",
            "1435/1435 [==============================] - ETA: 0s - loss: 0.7118 - accuracy: 0.7826\n",
            "Epoch 41: val_accuracy did not improve from 0.66574\n",
            "\n",
            "Epoch 41: ReduceLROnPlateau reducing learning rate to 1.0000000830368326e-17.\n",
            "1435/1435 [==============================] - 137s 95ms/step - loss: 0.7118 - accuracy: 0.7826 - val_loss: 1.0779 - val_accuracy: 0.6639 - lr: 1.0000e-16\n",
            "Epoch 42/80\n",
            "1435/1435 [==============================] - ETA: 0s - loss: 0.7156 - accuracy: 0.7819\n",
            "Epoch 42: val_accuracy did not improve from 0.66574\n",
            "1435/1435 [==============================] - 137s 95ms/step - loss: 0.7156 - accuracy: 0.7819 - val_loss: 1.0791 - val_accuracy: 0.6618 - lr: 1.0000e-17\n",
            "Epoch 43/80\n",
            "1435/1435 [==============================] - ETA: 0s - loss: 0.7146 - accuracy: 0.7834\n",
            "Epoch 43: val_accuracy did not improve from 0.66574\n",
            "\n",
            "Epoch 43: ReduceLROnPlateau reducing learning rate to 1.0000000664932204e-18.\n",
            "1435/1435 [==============================] - 138s 96ms/step - loss: 0.7146 - accuracy: 0.7834 - val_loss: 1.0790 - val_accuracy: 0.6624 - lr: 1.0000e-17\n",
            "Epoch 44/80\n",
            "1435/1435 [==============================] - ETA: 0s - loss: 0.7171 - accuracy: 0.7813\n",
            "Epoch 44: val_accuracy did not improve from 0.66574\n",
            "1435/1435 [==============================] - 138s 96ms/step - loss: 0.7171 - accuracy: 0.7813 - val_loss: 1.0789 - val_accuracy: 0.6624 - lr: 1.0000e-18\n",
            "Epoch 45/80\n",
            "1435/1435 [==============================] - ETA: 0s - loss: 0.7162 - accuracy: 0.7820\n",
            "Epoch 45: val_accuracy did not improve from 0.66574\n",
            "\n",
            "Epoch 45: ReduceLROnPlateau reducing learning rate to 1.000000045813705e-19.\n",
            "1435/1435 [==============================] - 139s 97ms/step - loss: 0.7162 - accuracy: 0.7820 - val_loss: 1.0758 - val_accuracy: 0.6632 - lr: 1.0000e-18\n",
            "Epoch 46/80\n",
            "1435/1435 [==============================] - ETA: 0s - loss: 0.7110 - accuracy: 0.7856\n",
            "Epoch 46: val_accuracy did not improve from 0.66574\n",
            "1435/1435 [==============================] - 139s 97ms/step - loss: 0.7110 - accuracy: 0.7856 - val_loss: 1.0762 - val_accuracy: 0.6640 - lr: 1.0000e-19\n",
            "Epoch 47/80\n",
            "1435/1435 [==============================] - ETA: 0s - loss: 0.7118 - accuracy: 0.7835\n",
            "Epoch 47: val_accuracy did not improve from 0.66574\n",
            "\n",
            "Epoch 47: ReduceLROnPlateau reducing learning rate to 1.000000032889008e-20.\n",
            "1435/1435 [==============================] - 137s 96ms/step - loss: 0.7118 - accuracy: 0.7835 - val_loss: 1.0766 - val_accuracy: 0.6626 - lr: 1.0000e-19\n",
            "Epoch 48/80\n",
            "1435/1435 [==============================] - ETA: 0s - loss: 0.7124 - accuracy: 0.7820\n",
            "Epoch 48: val_accuracy did not improve from 0.66574\n",
            "1435/1435 [==============================] - 135s 94ms/step - loss: 0.7124 - accuracy: 0.7820 - val_loss: 1.0754 - val_accuracy: 0.6626 - lr: 1.0000e-20\n",
            "Epoch 49/80\n",
            "1435/1435 [==============================] - ETA: 0s - loss: 0.7113 - accuracy: 0.7821\n",
            "Epoch 49: val_accuracy did not improve from 0.66574\n",
            "\n",
            "Epoch 49: ReduceLROnPlateau reducing learning rate to 1.0000000490448793e-21.\n",
            "1435/1435 [==============================] - 136s 95ms/step - loss: 0.7113 - accuracy: 0.7821 - val_loss: 1.0762 - val_accuracy: 0.6648 - lr: 1.0000e-20\n",
            "Epoch 50/80\n",
            "1435/1435 [==============================] - ETA: 0s - loss: 0.7141 - accuracy: 0.7841\n",
            "Epoch 50: val_accuracy did not improve from 0.66574\n",
            "1435/1435 [==============================] - 136s 95ms/step - loss: 0.7141 - accuracy: 0.7841 - val_loss: 1.0794 - val_accuracy: 0.6634 - lr: 1.0000e-21\n",
            "Epoch 51/80\n",
            "1435/1435 [==============================] - ETA: 0s - loss: 0.7174 - accuracy: 0.7816\n",
            "Epoch 51: val_accuracy did not improve from 0.66574\n",
            "\n",
            "Epoch 51: ReduceLROnPlateau reducing learning rate to 1.0000000692397185e-22.\n",
            "1435/1435 [==============================] - 135s 94ms/step - loss: 0.7174 - accuracy: 0.7816 - val_loss: 1.0789 - val_accuracy: 0.6632 - lr: 1.0000e-21\n",
            "Epoch 52/80\n",
            "1435/1435 [==============================] - ETA: 0s - loss: 0.7125 - accuracy: 0.7827\n",
            "Epoch 52: val_accuracy did not improve from 0.66574\n",
            "1435/1435 [==============================] - 137s 96ms/step - loss: 0.7125 - accuracy: 0.7827 - val_loss: 1.0757 - val_accuracy: 0.6634 - lr: 1.0000e-22\n",
            "Epoch 53/80\n",
            "1435/1435 [==============================] - ETA: 0s - loss: 0.7155 - accuracy: 0.7828\n",
            "Epoch 53: val_accuracy did not improve from 0.66574\n",
            "\n",
            "Epoch 53: ReduceLROnPlateau reducing learning rate to 1.0000000944832675e-23.\n",
            "1435/1435 [==============================] - 134s 93ms/step - loss: 0.7155 - accuracy: 0.7828 - val_loss: 1.0756 - val_accuracy: 0.6626 - lr: 1.0000e-22\n",
            "Epoch 54/80\n",
            "1435/1435 [==============================] - ETA: 0s - loss: 0.7151 - accuracy: 0.7819\n",
            "Epoch 54: val_accuracy did not improve from 0.66574\n",
            "1435/1435 [==============================] - 132s 92ms/step - loss: 0.7151 - accuracy: 0.7819 - val_loss: 1.0777 - val_accuracy: 0.6633 - lr: 1.0000e-23\n",
            "Epoch 55/80\n",
            "1435/1435 [==============================] - ETA: 0s - loss: 0.7150 - accuracy: 0.7803\n",
            "Epoch 55: val_accuracy did not improve from 0.66574\n",
            "\n",
            "Epoch 55: ReduceLROnPlateau reducing learning rate to 1.0000000787060494e-24.\n",
            "1435/1435 [==============================] - 130s 91ms/step - loss: 0.7150 - accuracy: 0.7803 - val_loss: 1.0773 - val_accuracy: 0.6627 - lr: 1.0000e-23\n",
            "Epoch 56/80\n",
            "1435/1435 [==============================] - ETA: 0s - loss: 0.7192 - accuracy: 0.7779\n",
            "Epoch 56: val_accuracy did not improve from 0.66574\n",
            "1435/1435 [==============================] - 133s 93ms/step - loss: 0.7192 - accuracy: 0.7779 - val_loss: 1.0776 - val_accuracy: 0.6632 - lr: 1.0000e-24\n",
            "Epoch 57/80\n",
            "1435/1435 [==============================] - ETA: 0s - loss: 0.7157 - accuracy: 0.7804\n",
            "Epoch 57: val_accuracy did not improve from 0.66574\n",
            "\n",
            "Epoch 57: ReduceLROnPlateau reducing learning rate to 1.0000001181490946e-25.\n",
            "1435/1435 [==============================] - 135s 94ms/step - loss: 0.7157 - accuracy: 0.7804 - val_loss: 1.0802 - val_accuracy: 0.6616 - lr: 1.0000e-24\n",
            "Epoch 58/80\n",
            "1435/1435 [==============================] - ETA: 0s - loss: 0.7141 - accuracy: 0.7811\n",
            "Epoch 58: val_accuracy did not improve from 0.66574\n",
            "1435/1435 [==============================] - 133s 93ms/step - loss: 0.7141 - accuracy: 0.7811 - val_loss: 1.0754 - val_accuracy: 0.6643 - lr: 1.0000e-25\n",
            "Epoch 59/80\n",
            "1435/1435 [==============================] - ETA: 0s - loss: 0.7124 - accuracy: 0.7833\n",
            "Epoch 59: val_accuracy did not improve from 0.66574\n",
            "\n",
            "Epoch 59: ReduceLROnPlateau reducing learning rate to 1.0000001428009978e-26.\n",
            "1435/1435 [==============================] - 134s 93ms/step - loss: 0.7124 - accuracy: 0.7833 - val_loss: 1.0778 - val_accuracy: 0.6627 - lr: 1.0000e-25\n",
            "Epoch 60/80\n",
            "1435/1435 [==============================] - ETA: 0s - loss: 0.7148 - accuracy: 0.7840\n",
            "Epoch 60: val_accuracy did not improve from 0.66574\n",
            "1435/1435 [==============================] - 134s 94ms/step - loss: 0.7148 - accuracy: 0.7840 - val_loss: 1.0755 - val_accuracy: 0.6620 - lr: 1.0000e-26\n",
            "Epoch 61/80\n",
            "1435/1435 [==============================] - ETA: 0s - loss: 0.7138 - accuracy: 0.7806\n",
            "Epoch 61: val_accuracy did not improve from 0.66574\n",
            "\n",
            "Epoch 61: ReduceLROnPlateau reducing learning rate to 1.000000142800998e-27.\n",
            "1435/1435 [==============================] - 137s 95ms/step - loss: 0.7138 - accuracy: 0.7806 - val_loss: 1.0811 - val_accuracy: 0.6618 - lr: 1.0000e-26\n",
            "Epoch 62/80\n",
            "1435/1435 [==============================] - ETA: 0s - loss: 0.7075 - accuracy: 0.7850\n",
            "Epoch 62: val_accuracy did not improve from 0.66574\n",
            "1435/1435 [==============================] - 135s 94ms/step - loss: 0.7075 - accuracy: 0.7850 - val_loss: 1.0785 - val_accuracy: 0.6636 - lr: 1.0000e-27\n",
            "Epoch 63/80\n",
            "1435/1435 [==============================] - ETA: 0s - loss: 0.7136 - accuracy: 0.7829\n",
            "Epoch 63: val_accuracy did not improve from 0.66574\n",
            "\n",
            "Epoch 63: ReduceLROnPlateau reducing learning rate to 1.0000001235416984e-28.\n",
            "1435/1435 [==============================] - 135s 94ms/step - loss: 0.7136 - accuracy: 0.7829 - val_loss: 1.0784 - val_accuracy: 0.6631 - lr: 1.0000e-27\n",
            "Epoch 64/80\n",
            "1435/1435 [==============================] - ETA: 0s - loss: 0.7127 - accuracy: 0.7828\n",
            "Epoch 64: val_accuracy did not improve from 0.66574\n",
            "1435/1435 [==============================] - 136s 94ms/step - loss: 0.7127 - accuracy: 0.7828 - val_loss: 1.0770 - val_accuracy: 0.6628 - lr: 1.0000e-28\n",
            "Epoch 65/80\n",
            "1435/1435 [==============================] - ETA: 0s - loss: 0.7149 - accuracy: 0.7812\n",
            "Epoch 65: val_accuracy did not improve from 0.66574\n",
            "\n",
            "Epoch 65: ReduceLROnPlateau reducing learning rate to 1.0000001235416985e-29.\n",
            "1435/1435 [==============================] - 134s 93ms/step - loss: 0.7149 - accuracy: 0.7812 - val_loss: 1.0745 - val_accuracy: 0.6634 - lr: 1.0000e-28\n",
            "Epoch 66/80\n",
            "1435/1435 [==============================] - ETA: 0s - loss: 0.7183 - accuracy: 0.7822\n",
            "Epoch 66: val_accuracy did not improve from 0.66574\n",
            "1435/1435 [==============================] - 135s 94ms/step - loss: 0.7183 - accuracy: 0.7822 - val_loss: 1.0747 - val_accuracy: 0.6630 - lr: 1.0000e-29\n",
            "Epoch 67/80\n",
            "1435/1435 [==============================] - ETA: 0s - loss: 0.7123 - accuracy: 0.7835\n",
            "Epoch 67: val_accuracy did not improve from 0.66574\n",
            "\n",
            "Epoch 67: ReduceLROnPlateau reducing learning rate to 1.0000001536343539e-30.\n",
            "1435/1435 [==============================] - 131s 91ms/step - loss: 0.7123 - accuracy: 0.7835 - val_loss: 1.0759 - val_accuracy: 0.6639 - lr: 1.0000e-29\n",
            "Epoch 68/80\n",
            "1435/1435 [==============================] - ETA: 0s - loss: 0.7109 - accuracy: 0.7825\n",
            "Epoch 68: val_accuracy did not improve from 0.66574\n",
            "1435/1435 [==============================] - 132s 92ms/step - loss: 0.7109 - accuracy: 0.7825 - val_loss: 1.0815 - val_accuracy: 0.6616 - lr: 1.0000e-30\n",
            "Epoch 69/80\n",
            "1435/1435 [==============================] - ETA: 0s - loss: 0.7156 - accuracy: 0.7814\n",
            "Epoch 69: val_accuracy did not improve from 0.66574\n",
            "\n",
            "Epoch 69: ReduceLROnPlateau reducing learning rate to 1.000000191250173e-31.\n",
            "1435/1435 [==============================] - 133s 92ms/step - loss: 0.7156 - accuracy: 0.7814 - val_loss: 1.0746 - val_accuracy: 0.6630 - lr: 1.0000e-30\n",
            "Epoch 70/80\n",
            "1435/1435 [==============================] - ETA: 0s - loss: 0.7160 - accuracy: 0.7796\n",
            "Epoch 70: val_accuracy did not improve from 0.66574\n",
            "1435/1435 [==============================] - 133s 93ms/step - loss: 0.7160 - accuracy: 0.7796 - val_loss: 1.0751 - val_accuracy: 0.6632 - lr: 1.0000e-31\n",
            "Epoch 71/80\n",
            "1435/1435 [==============================] - ETA: 0s - loss: 0.7122 - accuracy: 0.7827\n",
            "Epoch 71: val_accuracy did not improve from 0.66574\n",
            "\n",
            "Epoch 71: ReduceLROnPlateau reducing learning rate to 1.0000002147600601e-32.\n",
            "1435/1435 [==============================] - 132s 92ms/step - loss: 0.7122 - accuracy: 0.7827 - val_loss: 1.0754 - val_accuracy: 0.6620 - lr: 1.0000e-31\n",
            "Epoch 72/80\n",
            "1435/1435 [==============================] - ETA: 0s - loss: 0.7135 - accuracy: 0.7818\n",
            "Epoch 72: val_accuracy did not improve from 0.66574\n",
            "1435/1435 [==============================] - 133s 93ms/step - loss: 0.7135 - accuracy: 0.7818 - val_loss: 1.0760 - val_accuracy: 0.6639 - lr: 1.0000e-32\n",
            "Epoch 73/80\n",
            "1435/1435 [==============================] - ETA: 0s - loss: 0.7145 - accuracy: 0.7815\n",
            "Epoch 73: val_accuracy did not improve from 0.66574\n",
            "\n",
            "Epoch 73: ReduceLROnPlateau reducing learning rate to 1.0000002441474188e-33.\n",
            "1435/1435 [==============================] - 132s 92ms/step - loss: 0.7145 - accuracy: 0.7815 - val_loss: 1.0807 - val_accuracy: 0.6623 - lr: 1.0000e-32\n",
            "Epoch 74/80\n",
            "1435/1435 [==============================] - ETA: 0s - loss: 0.7107 - accuracy: 0.7848\n",
            "Epoch 74: val_accuracy did not improve from 0.66574\n",
            "1435/1435 [==============================] - 132s 92ms/step - loss: 0.7107 - accuracy: 0.7848 - val_loss: 1.0755 - val_accuracy: 0.6640 - lr: 1.0000e-33\n",
            "Epoch 75/80\n",
            "1435/1435 [==============================] - ETA: 0s - loss: 0.7157 - accuracy: 0.7813\n",
            "Epoch 75: val_accuracy did not improve from 0.66574\n",
            "\n",
            "Epoch 75: ReduceLROnPlateau reducing learning rate to 1.0000002074132203e-34.\n",
            "1435/1435 [==============================] - 132s 92ms/step - loss: 0.7157 - accuracy: 0.7813 - val_loss: 1.0741 - val_accuracy: 0.6652 - lr: 1.0000e-33\n",
            "Epoch 76/80\n",
            "1435/1435 [==============================] - ETA: 0s - loss: 0.7173 - accuracy: 0.7807\n",
            "Epoch 76: val_accuracy did not improve from 0.66574\n",
            "1435/1435 [==============================] - 132s 92ms/step - loss: 0.7173 - accuracy: 0.7807 - val_loss: 1.0729 - val_accuracy: 0.6632 - lr: 1.0000e-34\n",
            "Epoch 77/80\n",
            "1435/1435 [==============================] - ETA: 0s - loss: 0.7148 - accuracy: 0.7810\n",
            "Epoch 77: val_accuracy did not improve from 0.66574\n",
            "\n",
            "Epoch 77: ReduceLROnPlateau reducing learning rate to 1.0000001614954722e-35.\n",
            "1435/1435 [==============================] - 131s 91ms/step - loss: 0.7148 - accuracy: 0.7810 - val_loss: 1.0776 - val_accuracy: 0.6641 - lr: 1.0000e-34\n",
            "Epoch 78/80\n",
            "1435/1435 [==============================] - ETA: 0s - loss: 0.7205 - accuracy: 0.7787\n",
            "Epoch 78: val_accuracy did not improve from 0.66574\n",
            "1435/1435 [==============================] - 132s 92ms/step - loss: 0.7205 - accuracy: 0.7787 - val_loss: 1.0797 - val_accuracy: 0.6630 - lr: 1.0000e-35\n",
            "Epoch 79/80\n",
            "1435/1435 [==============================] - ETA: 0s - loss: 0.7167 - accuracy: 0.7806\n",
            "Epoch 79: val_accuracy did not improve from 0.66574\n",
            "\n",
            "Epoch 79: ReduceLROnPlateau reducing learning rate to 1.0000001614954723e-36.\n",
            "1435/1435 [==============================] - 133s 93ms/step - loss: 0.7167 - accuracy: 0.7806 - val_loss: 1.0763 - val_accuracy: 0.6643 - lr: 1.0000e-35\n",
            "Epoch 80/80\n",
            "1435/1435 [==============================] - ETA: 0s - loss: 0.7168 - accuracy: 0.7801\n",
            "Epoch 80: val_accuracy did not improve from 0.66574\n",
            "1435/1435 [==============================] - 133s 93ms/step - loss: 0.7168 - accuracy: 0.7801 - val_loss: 1.0786 - val_accuracy: 0.6630 - lr: 1.0000e-36\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f1950c17940>"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "puSVxsnR0JQD"
      },
      "source": [
        "### saving the trained model and loading it"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W2aYcGUd0JQE"
      },
      "outputs": [],
      "source": [
        "# # use below line to save the trained model \n",
        "# cnn_model.save('/content/drive/MyDrive/DataBasesML/face_emotions/model.h5')\n",
        "\n",
        "# ## use below line to use the trained model in seperate file\n",
        "# # loaded_model = tf.keras.models.load_model('path/to/save/model.h5')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## evaluate model"
      ],
      "metadata": {
        "id": "J0eZvaO6YlN4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = cnn_model \n",
        "loss, acc = model.evaluate(training_set, verbose=2)\n",
        "loss, acc = model.evaluate(test_set, verbose=2)\n",
        "\n",
        "# Loads the weights\n",
        "cnn_model.load_weights(checkpoint_path(model_name=model_name))\n",
        "\n",
        "# Re-evaluate the model\n",
        "loss, acc = cnn_model.evaluate(test_set, verbose=2)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A1Xu7H99Ynjx",
        "outputId": "666c6af2-f7c7-4ba2-e0fb-20671dbbd596"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1436/1436 - 70s - loss: 0.5919 - accuracy: 0.8286 - 70s/epoch - 49ms/step\n",
            "449/449 - 10s - loss: 1.0790 - accuracy: 0.6631 - 10s/epoch - 22ms/step\n",
            "449/449 - 10s - loss: 1.0561 - accuracy: 0.6659 - 10s/epoch - 22ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U3PZasO0006Z"
      },
      "source": [
        "## Part 4 - Making a single prediction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "gsSiWEJY1BPB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "50a33e8c-61c8-4112-82a1-3e7a1be13feb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 90ms/step\n",
            "{'angry': 0, 'disgust': 1, 'fear': 2, 'happy': 3, 'neutral': 4, 'sad': 5, 'surprise': 6}\n",
            "surprise   6\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import keras.utils as image\n",
        "\n",
        "test_image = image.load_img('/content/single/9.jpg', target_size=(48, 48))\n",
        "test_image = image.img_to_array(test_image)\n",
        "test_image = np.expand_dims(test_image, axis=0)\n",
        "\n",
        "result = cnn_model.predict(test_image)\n",
        "class_indices = training_set.class_indices\n",
        "print(class_indices)\n",
        "\n",
        "predicted_class_index = np.argmax(result[0])\n",
        "for key, val in class_indices.items():\n",
        "        if val == predicted_class_index:\n",
        "            predicted_class = key\n",
        "\n",
        "print(predicted_class,\" \",predicted_class_index)"
      ]
    }
  ]
}